{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementation of Advanced Feature Selection and Classificaion Techniques with Optimization of Hyperparameters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWtfasPOdLhR",
        "colab_type": "code",
        "outputId": "5a51a9f9-67d2-4a6c-dbc5-b74d1e04c700",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "#to use a local file in google collab\n",
        "from google.colab import files \n",
        "\n",
        "#upload a file to collab using the browse button\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e619e94-d190-40ea-8f0f-131f1490d5e7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7e619e94-d190-40ea-8f0f-131f1490d5e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Gear25.csv to Gear25.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGNV5udyxj7X",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLG8prk3dQ93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "#import libraries to implement different classifiers\n",
        "#import library to split test and train data\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "#libraries for authenticating a user to link a google account to access spreadhsheets\n",
        "#then importing google spreadsheets\n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "import gspread  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt2oGLKUUs3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "c2eebbb1-cca6-495f-96f8-cd4635a86017"
      },
      "source": [
        "#authenticate a user \n",
        "#user needs to go to the link and select a google account to be linked\n",
        "#then the user needs to give permission for access\n",
        "#once permission is granted google speadsheet will be linked with the authenticated account\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#create a google spreadsheet with this name \"G25_out\"\n",
        "sh = gc.create('G25_out.csv')\n",
        "\n",
        "#decode and read the dataset\n",
        "df = pd.read_csv(io.StringIO(uploaded['Gear25.csv'].decode('utf-8'))) \n",
        "\n",
        "#to remove columns with 0's\n",
        "df = df.loc[: , (df!= 0).any(axis = 0)] \n",
        "\n",
        "#Takes all rows of all columns except the last column\n",
        "X = df.iloc[:,:-1].values\n",
        "\n",
        "#Takes all rows of the last column\n",
        "Y = df.iloc[:,-1].values \n",
        "\n",
        "#open the google spreadsheet\n",
        "#the output of this code will be updated to this google spreadsheet\n",
        "#this spreadsheet can be accessed from google drive\n",
        "worksheet = gc.open('G25_out.csv').sheet1 "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HT8upxvU9QD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "922fa73a-0454-4faa-aed6-0c8ae9321b79"
      },
      "source": [
        "#our aim is to get the output from fold no#1 to no#10\n",
        "#loop variable is used to change the cross_validation values from 1 to 10\n",
        "loop = 1\n",
        "for x in range (1,11): \n",
        "  if loop >= 2: \n",
        "    \n",
        "    #to assign the loop value to variable x\n",
        "    #this variable x is the crossvalidation value\n",
        "    cv = x\n",
        "    \n",
        "    #splitting data into test and train\n",
        "    #test data is 20%\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2) \n",
        "    \n",
        "    #Fit to data, then transform it\n",
        "    #Perform standardization by centering and scaling\n",
        "    sc_X = StandardScaler()\n",
        "    X_train = sc_X.fit_transform(X_train) \n",
        "    X_test = sc_X.transform(X_test)\n",
        "     \n",
        "    #prints the number of folds\n",
        "    print(\"for CV value =\",cv,\"we have the following output:\\n\")\n",
        "    \n",
        "    #for RandomForest classifier and tuning hyperparameter\n",
        "    clf = RandomForestClassifier(n_estimators=100) \n",
        "    np.mean(cross_val_score(clf, X_train, Y_train, cv=cv))\n",
        "    clf.fit(X_train,Y_train)\n",
        "    clf_predict = clf.predict(X_test) \n",
        "    \n",
        "    #for RBF classifier and tuning hyperparameter\n",
        "    svclassifier = SVC(kernel='rbf', gamma='scale', C= 1000)\n",
        "    np.mean(cross_val_score(svclassifier, X_train, Y_train, cv=cv))\n",
        "    svclassifier.fit(X_train, Y_train) \n",
        "    svc_predictions = svclassifier.predict(X_test) \n",
        "    \n",
        "    #codes works fine but takes too much time to process\n",
        "    #to test output uncomment this from here...\n",
        "    #for Multi Layer Perceptron classifier and tuning hyperparameter\n",
        "    #mlp = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=1200)  \n",
        "    #np.mean(cross_val_score(mlp, X_train, Y_train, cv=cv)) \n",
        "    #mlp.fit(X_train, Y_train) \n",
        "    #mlp_predictions = mlp.predict(X_test)\n",
        "    \n",
        "    #for Decision tree classifier\n",
        "    DT = DecisionTreeClassifier()\n",
        "    np.mean(cross_val_score(svclassifier, X_train, Y_train, cv=cv))\n",
        "    DT.fit(X_train,Y_train)\n",
        "    DT_predictions = DT.predict(X_test)\n",
        "    \n",
        "    #for k-NN classifier with neighbors = 1 \n",
        "    knn = KNeighborsClassifier(n_neighbors=1) \n",
        "    np.mean(cross_val_score(knn, X_train, Y_train, cv=cv)) \n",
        "    knn.fit(X_train, Y_train) \n",
        "    knn_predictions = knn.predict(X_test)\n",
        "    \n",
        "    #print the output\n",
        "    #update the google sheet with the outputs\n",
        "    #for RF\n",
        "    print('RF F1score:', f1_score(Y_test, clf_predict, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 1, f1_score(Y_test, clf_predict, average= 'weighted'))\n",
        "    print('RF Accuracy:', accuracy_score(Y_test, clf_predict))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 2, accuracy_score(Y_test, clf_predict))\n",
        "    \n",
        "    #for RBF\n",
        "    print('RBF F1score:', f1_score(Y_test, svc_predictions, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 3, f1_score(Y_test, svc_predictions, average= 'weighted'))                                  \n",
        "    print('RBF Accuracy:', accuracy_score(Y_test, svc_predictions))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 4, accuracy_score(Y_test, svc_predictions))  \n",
        "    \n",
        "    #uncomment to check f1 score of MLP\n",
        "    #results for MLP have not been linked to google spreadsheet\n",
        "    #print('MLP F1score:', f1_score(Y_test, mlp_predictions, average= 'weighted'))\n",
        "    #uncomment to check accuracy of MLP\n",
        "    #results for MLP have not been linked to google spreadsheet\n",
        "    #print('MLP Accuracy:', accuracy_score(Y_test, mlp_predictions))\n",
        "    \n",
        "    #for DT\n",
        "    print('DT F1score:', accuracy_score(Y_test, DT_predictions))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 5, f1_score(Y_test, DT_predictions, average= 'weighted'))                                       \n",
        "    print('DT Accuracy:', accuracy_score(Y_test, DT_predictions))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 6, accuracy_score(Y_test, DT_predictions))\n",
        "    \n",
        "    #for k-NN\n",
        "    print('kNN F1score:', f1_score(Y_test, knn_predictions, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 7, f1_score(Y_test, knn_predictions, average= 'weighted'))                                  \n",
        "    print('kNN F1score:', accuracy_score(Y_test, knn_predictions))\n",
        "    cell_list = worksheet.update_cell(cv + 1, 8, accuracy_score(Y_test, knn_predictions))\n",
        "    print(\"\\n\")\n",
        "\n",
        "  if loop < 2: \n",
        "    \n",
        "    loop = loop +1 \n",
        "    print(\"for CV value =\",1,\"we have the following output:\\n\")\n",
        "    \n",
        "    #splitting data into test and train\n",
        "    #test data is 20%\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2) \n",
        "    \n",
        "    #Fit to data, then transform it\n",
        "    #Perform standardization by centering and scaling\n",
        "    sc_X = StandardScaler()\n",
        "    X_train = sc_X.fit_transform(X_train) \n",
        "    X_test = sc_X.transform(X_test)\n",
        "\n",
        "    #for RandomForest classifier and tuning hyperparameter\n",
        "    clf = RandomForestClassifier(n_estimators=100)\n",
        "    clf.fit(X_train,Y_train)\n",
        "    clf_predict = clf.predict(X_test)\n",
        "    \n",
        "    #for RBF classifier and tuning hyperparameter\n",
        "    svclassifier = SVC(kernel='rbf',gamma='scale', C= 1000)\n",
        "    svclassifier.fit(X_train, Y_train)\n",
        "    svc_predictions = svclassifier.predict(X_test)\n",
        "    \n",
        "    #codes works fine but takes too much time to process\n",
        "    #to test output uncomment this from here...\n",
        "    #for Multi Layer Perceptron classifier and tuning hyperparameter\n",
        "    #mlp = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=1200) \n",
        "    #mlp.fit(X_train, Y_train)\n",
        "    #mlp_predictions = mlp.predict(X_test)\n",
        "    \n",
        "    #for Decision tree classifier\n",
        "    DT = DecisionTreeClassifier()\n",
        "    DT.fit(X_train,Y_train)\n",
        "    DT_predictions = DT.predict(X_test)\n",
        "    \n",
        "    #for k-NN classifier with neighbors = 1 \n",
        "    knn = KNeighborsClassifier(n_neighbors=1)\n",
        "    knn.fit(X_train, Y_train) \n",
        "    knn_predictions = knn.predict(X_test) \n",
        "    \n",
        "    #providing columns with headers labels in google spreadsheet\n",
        "    cell_list = worksheet.update_cell(1,1, 'RF- F1')\n",
        "    cell_list = worksheet.update_cell(1,2, 'RF- ACC')\n",
        "    cell_list = worksheet.update_cell(1,3, 'RBF- F1')\n",
        "    cell_list = worksheet.update_cell(1,4, 'RBF- ACC')\n",
        "    cell_list = worksheet.update_cell(1,5, 'DT- F1')\n",
        "    cell_list = worksheet.update_cell(1,6, 'DT- ACC')\n",
        "    cell_list = worksheet.update_cell(1,7, 'kNN- F1')\n",
        "    cell_list = worksheet.update_cell(1,8, 'kNN- ACC')\n",
        "    \n",
        "    #print the output\n",
        "    #update the google sheet with the outputs\n",
        "    #for RF\n",
        "    print('RF F1score:', f1_score(Y_test, clf_predict, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(2, 1, f1_score(Y_test, clf_predict, average= 'weighted'))\n",
        "    print('RF Accuracy:',accuracy_score(Y_test, clf_predict))\n",
        "    cell_list = worksheet.update_cell(2, 2, accuracy_score(Y_test, clf_predict))\n",
        "    \n",
        "    #for RBF\n",
        "    print('RBF F1score:', f1_score(Y_test, svc_predictions, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(2, 3, f1_score(Y_test, svc_predictions, average= 'weighted'))                                  \n",
        "    print('RBF Accuracy:', accuracy_score(Y_test, svc_predictions))\n",
        "    cell_list = worksheet.update_cell(2, 4, accuracy_score(Y_test, svc_predictions)) \n",
        "    \n",
        "    #uncomment to check f1 score of MLP\n",
        "    #results for MLP have not been linked to google spreadsheet\n",
        "    #print('MLP F1score:', f1_score(Y_test, mlp_predictions, average= 'weighted'))\n",
        "    #uncomment to check accuracy of MLP\n",
        "    #results for MLP have not been linked to google spreadsheet                               \n",
        "    #print('MLP Accuracy:', accuracy_score(Y_test, mlp_predictions))\n",
        "\n",
        "    #for DT\n",
        "    print('DT F1score:', accuracy_score(Y_test, DT_predictions))\n",
        "    cell_list = worksheet.update_cell(2, 5, f1_score(Y_test, DT_predictions, average= 'weighted'))\n",
        "    print('DT Accuracy:', accuracy_score(Y_test, DT_predictions))\n",
        "    cell_list = worksheet.update_cell(2, 6, accuracy_score(Y_test, DT_predictions))                                      \n",
        "    \n",
        "    #for k-NN\n",
        "    print('kNN F1score:', f1_score(Y_test, knn_predictions, average= 'weighted'))\n",
        "    cell_list = worksheet.update_cell(2, 7, f1_score(Y_test, knn_predictions, average= 'weighted'))                                  \n",
        "    print('kNN F1score:', accuracy_score(Y_test, knn_predictions))\n",
        "    cell_list = worksheet.update_cell(2, 8, accuracy_score(Y_test, knn_predictions))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for CV value = 1 we have the following output:\n",
            "\n",
            "RF F1score: 0.9982459370770531\n",
            "RF Accuracy: 0.99825\n",
            "RBF F1score: 0.9671318684688324\n",
            "RBF Accuracy: 0.959\n",
            "DT F1score: 0.99825\n",
            "DT Accuracy: 0.99825\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n",
            "for CV value = 2 we have the following output:\n",
            "\n",
            "RF F1score: 0.9983751197212323\n",
            "RF Accuracy: 0.998375\n",
            "RBF F1score: 0.9701925581793346\n",
            "RBF Accuracy: 0.962625\n",
            "DT F1score: 0.998375\n",
            "DT Accuracy: 0.998375\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n",
            "for CV value = 3 we have the following output:\n",
            "\n",
            "RF F1score: 0.9978772329521425\n",
            "RF Accuracy: 0.997875\n",
            "RBF F1score: 0.9687003736127294\n",
            "RBF Accuracy: 0.9615\n",
            "DT F1score: 0.997875\n",
            "DT Accuracy: 0.997875\n",
            "kNN F1score: 0.999501023292927\n",
            "kNN F1score: 0.9995\n",
            "\n",
            "\n",
            "for CV value = 4 we have the following output:\n",
            "\n",
            "RF F1score: 0.9975124713577868\n",
            "RF Accuracy: 0.9975\n",
            "RBF F1score: 0.9672864768845275\n",
            "RBF Accuracy: 0.95875\n",
            "DT F1score: 0.9975\n",
            "DT Accuracy: 0.9975\n",
            "kNN F1score: 0.9993750775693027\n",
            "kNN F1score: 0.999375\n",
            "\n",
            "\n",
            "for CV value = 5 we have the following output:\n",
            "\n",
            "RF F1score: 0.997887102283818\n",
            "RF Accuracy: 0.997875\n",
            "RBF F1score: 0.9684459765351926\n",
            "RBF Accuracy: 0.96075\n",
            "DT F1score: 0.997875\n",
            "DT Accuracy: 0.997875\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n",
            "for CV value = 6 we have the following output:\n",
            "\n",
            "RF F1score: 0.9976240297172951\n",
            "RF Accuracy: 0.997625\n",
            "RBF F1score: 0.9652490257081229\n",
            "RBF Accuracy: 0.957625\n",
            "DT F1score: 0.997625\n",
            "DT Accuracy: 0.997625\n",
            "kNN F1score: 0.9996249674913744\n",
            "kNN F1score: 0.999625\n",
            "\n",
            "\n",
            "for CV value = 7 we have the following output:\n",
            "\n",
            "RF F1score: 0.9978721102496968\n",
            "RF Accuracy: 0.997875\n",
            "RBF F1score: 0.9681858050561438\n",
            "RBF Accuracy: 0.9605\n",
            "DT F1score: 0.997875\n",
            "DT Accuracy: 0.997875\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n",
            "for CV value = 8 we have the following output:\n",
            "\n",
            "RF F1score: 0.9980014008892654\n",
            "RF Accuracy: 0.998\n",
            "RBF F1score: 0.9698496605640011\n",
            "RBF Accuracy: 0.962375\n",
            "DT F1score: 0.998\n",
            "DT Accuracy: 0.998\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n",
            "for CV value = 9 we have the following output:\n",
            "\n",
            "RF F1score: 0.9977624699284243\n",
            "RF Accuracy: 0.99775\n",
            "RBF F1score: 0.9672649750171068\n",
            "RBF Accuracy: 0.958625\n",
            "DT F1score: 0.99775\n",
            "DT Accuracy: 0.99775\n",
            "kNN F1score: 0.9993751130248646\n",
            "kNN F1score: 0.999375\n",
            "\n",
            "\n",
            "for CV value = 10 we have the following output:\n",
            "\n",
            "RF F1score: 0.998383440829839\n",
            "RF Accuracy: 0.998375\n",
            "RBF F1score: 0.9673039824827605\n",
            "RBF Accuracy: 0.95925\n",
            "DT F1score: 0.998375\n",
            "DT Accuracy: 0.998375\n",
            "kNN F1score: 1.0\n",
            "kNN F1score: 1.0\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}